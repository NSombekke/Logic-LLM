#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=2
#SBATCH --job-name=Run_Baselines
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=2:00:00
#SBATCH --output=./slurm_output/slurm_output_%A.out

module purge
module load 2023
module load Anaconda3/2023.07-2
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
source activate DL

cd $HOME/Logic-LLM/

MODEL_NAME="NousResearch/Meta-Llama-3-70B-GGUF"
Q_TYPE="Q4_K_M"

API_KEY="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"
DATASET_NAMES=("FOLIO")
MODES=("CoT")

rm -rf ~/.cache/huggingface/hub/models--NousResearch--Meta-Llama-3-70B-GGUF/

for dataset_name in "${DATASET_NAMES[@]}"
do
    for mode in "${MODES[@]}"
    do
        echo "Running baselines for $dataset_name with $mode for $MODEL_NAME model"
        python src/models/model_baseline.py \
            --api_key "$API_KEY" \
            --dataset_name "$dataset_name" \
            --framework "huggingface" \
            --split "dev" \
            --model_name "$MODEL_NAME" \
            --mode "$mode" \
            --is_GGUF \
            --Q_type "$Q_TYPE"
    done
done
